{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark Structured API\n",
    "- The Structured APIs are a tool for manipulating all sorts of data.\n",
    "- Unstructured log files to semi-structured CSV files.\n",
    "- Highly structured Parquet files. \n",
    "- These APIs refer to the following core types of distributed collection:\n",
    "- SQL tables and views,  DataFrames and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark SQL\n",
    "- You can run SQL queries against views or tables organized into databases\n",
    "- You also can use system functions or define user functions and analyze query plans in order to optimize their workloads.\n",
    "- This integrates directly into the DataFrame and Dataset API\n",
    "- You can choose to express some of your data manipulations in SQL and others in DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import depedicies\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark =SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tables\n",
    "- CREATE and DROP tables\n",
    "- Create table from .json file\n",
    "- Create table from .csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop table flights\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS flights\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table 'flights' with columns\n",
    "# DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG\n",
    "# From .json file:path Resources/20015-summary.json\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE flights (\n",
    "DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG)\n",
    "USING JSON OPTIONS (path '/Resources/2015-summary.json')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop flights_csv\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS flights_csv\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create table 'flights_csv' with columns\n",
    "# DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count LONG\n",
    "# From .csv file 20015-summary.csv\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE flights_csv (\n",
    "DEST_COUNTRY_NAME STRING,\n",
    "ORIGIN_COUNTRY_NAME STRING COMMENT \"remember, the US will be most prevalent\",\n",
    "count LONG)\n",
    "USING csv OPTIONS (header true, path '/Resources/2015-summary.csv')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Views\n",
    "- Creating Views\n",
    "- Creating Temporary views that are available only during the curent session\n",
    "- Overwrite and replace view if one already exists from previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a view(just_usa_view) in which the des_country_name is United States in order to see only those flights:\n",
    "spark.sql(\"\"\"\n",
    "CREATE VIEW just_usa_view AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a temporary view(just_usa_view) in which the destination is United States in order to see only those flights\n",
    "spark.sql(\"\"\"\n",
    "CREATE TEMP VIEW just_usa_view_temp AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overwrite and replace view(just_usa_view) if one already exists from previous \n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMP VIEW just_usa_view_temp AS\n",
    "SELECT * FROM flights WHERE dest_country_name = 'United States'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Transformations\n",
    "- Adding/removing rows \n",
    "- Transform row into column(or vice versa)\n",
    "- Changing the order of rows based on the values in columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame and register as a temporary view to query it in SQL(SQL trasformations)\n",
    "# For Quering in SQL, name the SQL dataset table  (2015-summary-json)\n",
    "df = spark.read.format(\"json\").load(\"Resources/2015-summary.json\")\n",
    "df.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n",
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "|            Egypt|      United States|   15|\n",
      "|    United States|              India|   62|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----------------+-------------------+------------------+\n",
      "|summary|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|             count|\n",
      "+-------+-----------------+-------------------+------------------+\n",
      "|  count|              256|                256|               256|\n",
      "|   mean|             null|               null|       1770.765625|\n",
      "| stddev|             null|               null|23126.516918551915|\n",
      "|    min|          Algeria|             Angola|                 1|\n",
      "|    max|           Zambia|            Vietnam|            370002|\n",
      "+-------+-----------------+-------------------+------------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) FileScan json [DEST_COUNTRY_NAME#9,ORIGIN_COUNTRY_NAME#10,count#11L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/C:/Users/tenle/Documents/Web/Spark API Structured Operations/Resources/20..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:bigint>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('DEST_COUNTRY_NAME', 'string'),\n",
       " ('ORIGIN_COUNTRY_NAME', 'string'),\n",
       " ('count', 'bigint')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the schema(StructType) of the dataFrame: Schemas define the name as well as the type of data in each column\n",
    "# Return the the first five column records\n",
    "# Return statistics for numeric columns\n",
    "# Return the logical and physical plans. DataFrame lineage(how Spark executes query)\n",
    "# Return the datatypes\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "df.describe().show()\n",
    "df.explain()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From the df table return the DES_COUNTRY_Name column(return 2 rows)\n",
    "df.selectExpr(\"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding,Renaming and Dropping Columns\n",
    "- using as [column_name]\n",
    "- using withColumn method\n",
    "- using the withColumnRenamed method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column withinCountry to our DataFrame that specifies whether the destination and origin are the same:\n",
    "df.selectExpr(\n",
    "\"*\", # all original columns\n",
    "\"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) as withinCountry\")\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+---------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|numberOne|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "|    United States|            Romania|   15|        1|\n",
      "|    United States|            Croatia|    1|        1|\n",
      "+-----------------+-------------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a column name [numberOne] with values of 1, us withColumn method\n",
    "df.withColumn(\"numberOne\", lit(1)).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+-------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|withinCountry|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "|    United States|            Romania|   15|        false|\n",
      "|    United States|            Croatia|    1|        false|\n",
      "+-----------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set a Boolean flag for when the origin country is the same as the destination country\n",
    "df.withColumn(\"withinCountry\", expr(\"ORIGIN_COUNTRY_NAME == DEST_COUNTRY_NAME\"))\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dest', 'ORIGIN_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the DEST_COUNTRY_NAME column to desc\n",
    "df.withColumnRenamed(\"DEST_COUNTRY_NAME\", \"dest\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEST_COUNTRY_NAME', 'count']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the ORIGIN_COUNTRY_NAME columns\n",
    "df.drop(\"ORIGIN_COUNTRY_NAME\").columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing a Column’s Type (cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: bigint, count2: bigint]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python let’s convert our count column from an integer to a type Long:\n",
    "df.withColumn(\"count2\", col(\"count\").cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count2|\n",
      "+-----------------+-------------------+-----+------+\n",
      "|    United States|            Romania|   15|    15|\n",
      "|    United States|            Croatia|    1|     1|\n",
      "|    United States|            Ireland|  344|   344|\n",
      "+-----------------+-------------------+-----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL let’s convert our count column from an integer to a type Long:\n",
    "spark.sql(\"\"\"\n",
    "SELECT *, cast(count as long) AS count2 FROM dfTable\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering & Sorting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python - filter the count column returning values < 2\n",
    "# Origin_country_name is not equal to Crotia, show two rows\n",
    "df.where(col(\"count\") < 2).where(col(\"ORIGIN_COUNTRY_NAME\") != \"Croatia\")\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|          Singapore|    1|\n",
      "|          Moldova|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL - filter the count column returning values < 2\n",
    "# Origin_country_name is not equal to Crotia, show two rows\n",
    "spark.sql(\"\"\"\n",
    "SELECT * \n",
    "FROM dfTable \n",
    "WHERE count < 2 \n",
    "AND ORIGIN_COUNTRY_NAME != \"Croatia\"\n",
    "LIMIT 2\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the number of Unique rows from ORIGIN_COUNTRY_NAME\n",
    "df.select(\"ORIGIN_COUNTRY_NAME\",\"DEST_COUNTRY_NAME\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|count(DISTINCT named_struct(ORIGIN_COUNTRY_NAME, ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME, DEST_COUNTRY_NAME))|\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                         256|\n",
      "+------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT COUNT(DISTINCT(ORIGIN_COUNTRY_NAME, DEST_COUNTRY_NAME)) \n",
    "FROM dfTable\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|             Canada|  8483|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Python - Return the 'count' column in 'desc order' and the DEST_COUNTRY_NAME column in 'asceding order'\n",
    "df.orderBy(col(\"count\").desc(), col(\"DEST_COUNTRY_NAME\").asc()).show(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
